{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cirrus Demo\n",
    "\n",
    "## Simple Example\n",
    "\n",
    "This will run a simple logistic regression on the Criteo Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.genUID = function() {\n",
       "    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n",
       "        var r = Math.random()*16|0, v = c == 'x' ? r : (r&0x3|0x8);\n",
       "        return v.toString(16);\n",
       "    });\n",
       "};\n",
       "\n",
       "\n",
       "define('graphWidget', [\"@jupyter-widgets/base\"], function (widget) {\n",
       "\n",
       "    var GraphView = widget.DOMWidgetView.extend({\n",
       "        render: function(){\n",
       "            var that = this;\n",
       "\n",
       "            var graphId = window.genUID();\n",
       "            var loadingId = 'loading-'+graphId;\n",
       "\n",
       "\n",
       "            var _graph_url = that.model.get('_graph_url');\n",
       "\n",
       "            // variable plotlyDomain in the case of enterprise\n",
       "            var url_parts = _graph_url.split('/');\n",
       "            var plotlyDomain = url_parts[0] + '//' + url_parts[2];\n",
       "\n",
       "            if(!('plotlyDomains' in window)){\n",
       "                window.plotlyDomains = {};\n",
       "            }\n",
       "            window.plotlyDomains[graphId] = plotlyDomain;\n",
       "\n",
       "            // Place IFrame in output cell div `$el`\n",
       "            that.$el.css('width', '100%');\n",
       "            that.$graph = $(['<iframe id=\"'+graphId+'\"',\n",
       "                             'src=\"'+_graph_url+'.embed\"',\n",
       "                             'seamless',\n",
       "                             'style=\"border: none;\"',\n",
       "                             'width=\"100%\"',\n",
       "                             'height=\"600\">',\n",
       "                             '</iframe>'].join(' '));\n",
       "            that.$graph.appendTo(that.$el);\n",
       "\n",
       "            that.$loading = $('<div id=\"'+loadingId+'\">Initializing...</div>')\n",
       "                            .appendTo(that.$el);\n",
       "\n",
       "            // for some reason the 'width' is being changed in IPython 3.0.0\n",
       "            // for the containing `div` element. There's a flicker here, but\n",
       "            // I was unable to fix it otherwise.\n",
       "            setTimeout(function ()  {\n",
       "                if (IPYTHON_VERSION === '3') {\n",
       "                    $('#' + graphId)[0].parentElement.style.width = '100%';\n",
       "                }\n",
       "            }, 500);\n",
       "\n",
       "            // initialize communication with the iframe\n",
       "            if(!('pingers' in window)){\n",
       "                window.pingers = {};\n",
       "            }\n",
       "\n",
       "            window.pingers[graphId] = setInterval(function() {\n",
       "                that.graphContentWindow = $('#'+graphId)[0].contentWindow;\n",
       "                that.graphContentWindow.postMessage({task: 'ping'}, plotlyDomain);\n",
       "            }, 200);\n",
       "\n",
       "            // Assign a message listener to the 'message' events\n",
       "            // from iframe's postMessage protocol.\n",
       "            // Filter the messages by iframe src so that the right message\n",
       "            // gets passed to the right widget\n",
       "            if(!('messageListeners' in window)){\n",
       "                 window.messageListeners = {};\n",
       "            }\n",
       "\n",
       "            window.messageListeners[graphId] = function(e) {\n",
       "                if(_graph_url.indexOf(e.origin)>-1) {\n",
       "                    var frame = document.getElementById(graphId);\n",
       "\n",
       "                    if(frame === null){\n",
       "                        // frame doesn't exist in the dom anymore, clean up it's old event listener\n",
       "                        window.removeEventListener('message', window.messageListeners[graphId]);\n",
       "                        clearInterval(window.pingers[graphId]);\n",
       "                    } else if(frame.contentWindow === e.source) {\n",
       "                        // TODO: Stop event propagation, so each frame doesn't listen and filter\n",
       "                        var frameContentWindow = $('#'+graphId)[0].contentWindow;\n",
       "                        var message = e.data;\n",
       "\n",
       "                        if('pong' in message && message.pong) {\n",
       "                            $('#loading-'+graphId).hide();\n",
       "                            clearInterval(window.pingers[graphId]);\n",
       "                            that.send({event: 'pong', graphId: graphId});\n",
       "                        } else if (message.type==='hover' ||\n",
       "                                   message.type==='zoom'  ||\n",
       "                                   message.type==='click' ||\n",
       "                                   message.type==='unhover') {\n",
       "\n",
       "                            // click and hover events contain all of the data in the traces,\n",
       "                            // which can be a very large object and may take a ton of time\n",
       "                            // to pass to the python backend. Strip out the data, and require\n",
       "                            // the user to call get_figure if they need trace information\n",
       "                            if(message.type !== 'zoom') {\n",
       "                                for(var i in message.points) {\n",
       "                                    delete message.points[i].data;\n",
       "                                    delete message.points[i].fullData;\n",
       "                                }\n",
       "                            }\n",
       "                            that.send({event: message.type, message: message, graphId: graphId});\n",
       "                        } else if (message.task === 'getAttributes') {\n",
       "                            that.send({event: 'getAttributes', response: message.response});\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            };\n",
       "\n",
       "            window.removeEventListener('message', window.messageListeners[graphId]);\n",
       "            window.addEventListener('message', window.messageListeners[graphId]);\n",
       "\n",
       "        },\n",
       "\n",
       "        update: function() {\n",
       "            // Listen for messages from the graph widget in python\n",
       "            var jmessage = this.model.get('_message');\n",
       "            var message = JSON.parse(jmessage);\n",
       "\n",
       "            // check for duplicate messages\n",
       "            if(!('messageIds' in window)){\n",
       "                window.messageIds = {};\n",
       "            }\n",
       "\n",
       "            if(!(message.uid in window.messageIds)){\n",
       "                // message hasn't been received yet, do stuff\n",
       "                window.messageIds[message.uid] = true;\n",
       "\n",
       "                if (message.fadeTo) {\n",
       "                    this.fadeTo(message);\n",
       "                } else {\n",
       "                    var plot = $('#' + message.graphId)[0].contentWindow;\n",
       "                    plot.postMessage(message, window.plotlyDomains[message.graphId]);\n",
       "                }\n",
       "            }\n",
       "\n",
       "            return GraphView.__super__.update.apply(this);\n",
       "        },\n",
       "\n",
       "        /**\n",
       "         * Wrapper for jquery's `fadeTo` function.\n",
       "         *\n",
       "         * @param message Contains the id we need to find the element.\n",
       "         */\n",
       "        fadeTo: function (message) {\n",
       "            var plot = $('#' + message.graphId);\n",
       "            plot.fadeTo(message.duration, message.opacity);\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Register the GraphView with the widget manager.\n",
       "    return {\n",
       "        GraphView: GraphView\n",
       "    }\n",
       "\n",
       "});\n",
       "\n",
       "//@ sourceURL=graphWidget.js\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12 (default, Dec  4 2017, 14:50:18) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import cirrus\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import tools\n",
    "import plotly.tools as tls   \n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "from __future__ import print_function\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image, display, clear_output\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.widgets import GraphWidget\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import random\n",
    "\n",
    "class mock():\n",
    "    \n",
    "    def __init__(self, strid):\n",
    "        self.pipe = py.Stream(strid)\n",
    "        self.pipe.open()\n",
    "        self.kill_sig = threading.Event()\n",
    "    \n",
    "    def start_thread(self):\n",
    "        \n",
    "        def num_producer():\n",
    "            start_time = time.time()\n",
    "            \n",
    "            while not self.kill_sig.is_set():\n",
    "                time.sleep(0.5)\n",
    "                now_time = time.time()\n",
    "                integer = random.random()\n",
    "                self.pipe.write(dict(x = now_time - start_time, y = integer))\n",
    "        \n",
    "        self.thr = threading.Thread(target=num_producer)\n",
    "        self.thr.start()\n",
    "        \n",
    "    def kill(self):\n",
    "        print(\"Mock received kill command\")\n",
    "        self.kill_sig.set()\n",
    "        self.thr.join()\n",
    "        self.pipe.close()\n",
    "        print(\"Mock is dead\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Logistic Regression workload\n",
      "Starting LogisticRegressionTask\n",
      "Running Logistic Regression workload\n",
      "Starting LogisticRegressionTask\n"
     ]
    }
   ],
   "source": [
    "import cirrus\n",
    "\n",
    "\n",
    "\n",
    "data_bucket = 'cirrus-criteo-kaggle-19b-random'\n",
    "model = 'model_v1'\n",
    "\n",
    "lr_task = cirrus.LogisticRegression(\n",
    "             # number of workers\n",
    "             n_workers = 5,\n",
    "             # number of parameter servers\n",
    "             n_ps = 2,\n",
    "             # worker size in MB\n",
    "             worker_size = 128,\n",
    "             # path to s3 bucket with input dataset\n",
    "             dataset = data_bucket,\n",
    "             # sgd update LR and epsilon\n",
    "             learning_rate=0.01,\n",
    "             epsilon=0.0001,\n",
    "             progress_callback = print,\n",
    "             # stop workload after these many seconds\n",
    "             timeout = 0,\n",
    "             # stop workload once we reach this loss\n",
    "             threshold_loss=0,\n",
    "             # resume execution from model stored in this s3 bucket\n",
    "             resume_model = model,\n",
    "             # aws key name\n",
    "             key_name='mykey',\n",
    "             # path to aws key\n",
    "             key_path='/home/camus/Downloads/mykey.pem',\n",
    "             # ip where ps lives\n",
    "             ps_ip_public='ec2-18-237-250-161.us-west-2.compute.amazonaws.com',\n",
    "             ps_ip_private='172.31.10.1',\n",
    "             # username of VM\n",
    "             ps_username='ubuntu',\n",
    "             # choose between adagrad, sgd, nesterov, momentum\n",
    "             opt_method = 'adagrad',\n",
    "             # checkpoint model every x secs\n",
    "             checkpoint_model = 60,\n",
    "             #\n",
    "             minibatch_size=20,\n",
    "             # model size\n",
    "             model_bits=19,\n",
    "             # whether to filter gradient weights\n",
    "             use_grad_threshold=False,\n",
    "             # threshold value\n",
    "             grad_threshold=0.001,\n",
    "             # range of training minibatches\n",
    "             train_set=(0,824),\n",
    "             # range of testing minibatches\n",
    "             test_set=(835,840)\n",
    "             )\n",
    "\n",
    "lr_task1 = cirrus.LogisticRegression(\n",
    "             # number of workers\n",
    "             n_workers = 5,\n",
    "             # number of parameter servers\n",
    "             n_ps = 2,\n",
    "             # worker size in MB\n",
    "             worker_size = 128,\n",
    "             # path to s3 bucket with input dataset\n",
    "             dataset = data_bucket,\n",
    "             # sgd update LR and epsilon\n",
    "             learning_rate=0.01,\n",
    "             epsilon=0.0001,\n",
    "             progress_callback = print,\n",
    "             # stop workload after these many seconds\n",
    "             timeout = 0,\n",
    "             # stop workload once we reach this loss\n",
    "             threshold_loss=0,\n",
    "             # resume execution from model stored in this s3 bucket\n",
    "             resume_model = model,\n",
    "             # aws key name\n",
    "             key_name='mykey',\n",
    "             # path to aws key\n",
    "             key_path='/home/camus/Downloads/mykey.pem',\n",
    "             # ip where ps lives\n",
    "             ps_ip_public='ec2-34-216-121-188.us-west-2.compute.amazonaws.com',\n",
    "             ps_ip_private='172.31.0.131',\n",
    "             # username of VM\n",
    "             ps_username='ubuntu',\n",
    "             # choose between adagrad, sgd, nesterov, momentum\n",
    "             opt_method = 'adagrad',\n",
    "             # checkpoint model every x secs\n",
    "             checkpoint_model = 60,\n",
    "             #\n",
    "             minibatch_size=20,\n",
    "             # model size\n",
    "             model_bits=19,\n",
    "             # whether to filter gradient weights\n",
    "             use_grad_threshold=False,\n",
    "             # threshold value\n",
    "             grad_threshold=0.001,\n",
    "             # range of training minibatches\n",
    "             train_set=(0,824),\n",
    "             # range of testing minibatches\n",
    "             test_set=(835,840)\n",
    "             )\n",
    "\n",
    "\n",
    "#model, loss = lr_task.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://plot.ly/~andrewmzhang/16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63ccd63e8ee433e9c33702fbd25a375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_ids = tls.get_credentials_file()['stream_ids']\n",
    "\n",
    "# Get stream id from stream id list \n",
    "stream_id0 = stream_ids[0]\n",
    "stream_id1 = stream_ids[1]\n",
    "stream_id2 = stream_ids[2]\n",
    "stream_id3 = stream_ids[3]\n",
    "\n",
    "\n",
    "stream_0 = go.Stream(\n",
    "    token=stream_id0,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "stream_1 = go.Stream(\n",
    "    token=stream_id1,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "stream_2 = go.Stream(\n",
    "    token=stream_id2,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "stream_3 = go.Stream(\n",
    "    token=stream_id3,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    mode='lines+markers',\n",
    "    stream=stream_0         # (!) embed stream id, 1 per trace\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    xaxis='x2',\n",
    "    yaxis='y2',\n",
    "    stream=stream_1\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    xaxis='x3',\n",
    "    yaxis='y3',\n",
    "    stream=stream_2\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    xaxis='x4',\n",
    "    yaxis='y4',\n",
    "    stream=stream_3\n",
    ")\n",
    "data = [trace0, trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    xaxis3=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='y3'\n",
    "    ),\n",
    "    xaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='y4'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='x2'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='x4'\n",
    "    )\n",
    ")\n",
    "\n",
    "    \n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "url = py.plot(fig, filename='multiple-subplots', auto_open=False)\n",
    "print(url)\n",
    "g = GraphWidget(url)\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_handler(widget, msg):\n",
    "    print(msg)\n",
    "    global lr_task\n",
    "    if msg[0]['curveNumber'] == 0:\n",
    "        lr_task.kill()\n",
    "    if msg[0]['curveNumber'] == 1:\n",
    "        lr_task1.kill()\n",
    "\n",
    "pipe0 = py.Stream(stream_id0)\n",
    "pipe0.open()\n",
    "\n",
    "pipe1 = py.Stream(stream_id1)\n",
    "pipe1.open()\n",
    "\n",
    "def progress_callback0(time_loss, cost, task):\n",
    "    global pipe0\n",
    "    print(\"Current training loss:\", time_loss, \"current cost ($): \", cost)\n",
    "    pipe0.write(dict(x=time_loss[0], y=time_loss[1]))\n",
    "    \n",
    "def progress_callback1(time_loss, cost, task):\n",
    "    global pipe1\n",
    "    print(\"Current training loss:\", time_loss, \"current cost ($): \", cost)\n",
    "    pipe1.write(dict(x=time_loss[0], y=time_loss[1]))\n",
    "\n",
    "\n",
    "lr_task.progress_callback = progress_callback0\n",
    "lr_task1.progress_callback = progress_callback1\n",
    "\n",
    "\n",
    "g.on_click(message_handler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25dbb9920144aeca8e13054c515cba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description=u'Halt!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description=\"Halt!\")\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    lr_task.kill()\n",
    "    lr_task1.kill()\n",
    "\n",
    "\n",
    "button.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's specific ip: ec2-18-237-250-161.us-west-2.compute.amazonaws.com\n",
      "Copying ps to vm..\n",
      "Done waiting... Attempting to copy over binary\n",
      "Copied PS binary to VM\n",
      "Defining configuration file\n",
      "\n",
      "input_path: /mnt/efs/criteo_kaggle/train.csv \n",
      "input_type: csv\n",
      "num_classes: 2 \n",
      "num_features: 13 \n",
      "limit_cols: 14 \n",
      "normalize: 1 \n",
      "limit_samples: 50000000 \n",
      "s3_size: 50000 \n",
      "use_bias: 1 \n",
      "model_type: LogisticRegression \n",
      "minibatch_size: 20 \n",
      "learning_rate: 0.010000 \n",
      "epsilon: 0.000100 \n",
      "model_bits: 19 \n",
      "s3_bucket: cirrus-criteo-kaggle-19b-random \n",
      "use_grad_threshold: 0 \n",
      "grad_threshold: 0.001000 \n",
      "train_set: 0-824 \n",
      "test_set: 835-840\n",
      "\n",
      "Launching ps\n",
      "Launching parameter server\n",
      "('cmd:', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-18-237-250-161.us-west-2.compute.amazonaws.com \"nohup ./parameter_server --config config_lr.txt --nworkers 10000 --rank 1 &> ps_output &\"')\n",
      "Launching lambdas\n",
      "Starting error task\n",
      "('cmd', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-18-237-250-161.us-west-2.compute.amazonaws.com \"./parameter_server --config config_lr.txt --nworkers 10 --rank 2 --ps_ip \"172.31.10.1\"\" > error_out &')\n",
      "Lambdas have been launched\n",
      "User's specific ip: ec2-54-188-0-164.us-west-2.compute.amazonaws.com\n",
      "Copying ps to vm..\n",
      "Cost Model\n",
      "PS has 0 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (2.1177, 0.693042) current cost ($):  0.000382762968\n",
      "Current training loss: (4.193, 0.693042) current cost ($):  0.000510459644572\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (6.277, 0.693042) current cost ($):  0.000638005204773\n",
      "Current training loss: (8.303, 0.693042) current cost ($):  0.000765672949664\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (10.367, 0.693042) current cost ($):  0.000893336181577\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (12.474, 0.693042) current cost ($):  0.00102109385173\n",
      "Current training loss: (14.52, 0.693042) current cost ($):  0.00114876676299\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (16.566, 0.693042) current cost ($):  0.0012765378809\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (18.615, 0.693042) current cost ($):  0.00140424321874\n",
      "Current training loss: (20.693, 0.693042) current cost ($):  0.0015319158109\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (22.758, 0.693042) current cost ($):  0.00165978616873\n",
      "Current training loss: (24.792, 0.693042) current cost ($):  0.00178768073254\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (26.867, 0.693042) current cost ($):  0.00191551571592\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (28.946, 0.693042) current cost ($):  0.00204317160854\n",
      "Current training loss: (31.044, 0.693042) current cost ($):  0.00217107917945\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (33.105, 0.693042) current cost ($):  0.00229888115883\n",
      "Current training loss: (35.152, 0.693042) current cost ($):  0.00242652448502\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (37.196, 0.693042) current cost ($):  0.00255428935769\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (39.219, 0.693042) current cost ($):  0.00268210789986\n",
      "Current training loss: (41.263, 0.693042) current cost ($):  0.00280993434353\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (43.361, 0.693042) current cost ($):  0.00293769570611\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (45.442, 0.693042) current cost ($):  0.00306535887725\n",
      "Current training loss: (47.554, 0.693042) current cost ($):  0.00319314733289\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (49.638, 0.693042) current cost ($):  0.00332084846166\n",
      "Current training loss: (51.69, 0.693042) current cost ($):  0.00344853438002\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (53.788, 0.693042) current cost ($):  0.00370383359884\n",
      "Current training loss: (55.886, 0.693042) current cost ($):  0.00383167075513\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (57.937, 0.693042) current cost ($):  0.00395934033864\n",
      "Current training loss: (60.031, 0.693042) current cost ($):  0.00408721668339\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (62.121, 0.693042) current cost ($):  0.0042151740338\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (64.225, 0.693042) current cost ($):  0.00434309690628\n",
      "Current training loss: (66.322, 0.693042) current cost ($):  0.00447076369387\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (68.392, 0.693042) current cost ($):  0.00459857808774\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (70.441, 0.693042) current cost ($):  0.00472636133143\n",
      "Current training loss: (72.521, 0.693042) current cost ($):  0.00485402155469\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (74.556, 0.693042) current cost ($):  0.00498161549644\n",
      "Current training loss: (76.648, 0.693042) current cost ($):  0.0051095435201\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (78.727, 0.693042) current cost ($):  0.0052371855243\n",
      "Current training loss: (80.804, 0.693042) current cost ($):  0.00536493822562\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (82.876, 0.693042) current cost ($):  0.00549283025182\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (84.898, 0.693042) current cost ($):  0.00562061539491\n",
      "Current training loss: (86.978, 0.693042) current cost ($):  0.00574849537131\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (89.045, 0.693042) current cost ($):  0.00587649917348\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (91.14, 0.693042) current cost ($):  0.00600446831538\n",
      "Current training loss: (93.206, 0.693042) current cost ($):  0.00613226211974\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (95.26, 0.693042) current cost ($):  0.00626012936255\n",
      "Current training loss: (97.333, 0.693042) current cost ($):  0.00638807855314\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (99.395, 0.693042) current cost ($):  0.00651595036971\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (101.45, 0.693042) current cost ($):  0.00664381320591\n",
      "Current training loss: (103.5, 0.693042) current cost ($):  0.00677173907185\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (105.59, 0.693042) current cost ($):  0.00689958393211\n",
      "Current training loss: (107.69, 0.693042) current cost ($):  0.00702749748993\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (109.75, 0.693042) current cost ($):  0.00715513941816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (111.87, 0.693042) current cost ($):  0.0072830189539\n",
      "Current training loss: (113.95, 0.693042) current cost ($):  0.00741067536316\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (116.04, 0.693042) current cost ($):  0.00766580441081\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (118.08, 0.693042) current cost ($):  0.00779362766349\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (120.18, 0.693042) current cost ($):  0.00792137170353\n",
      "Current training loss: (122.21, 0.693042) current cost ($):  0.00804900044231\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (124.2, 0.693042) current cost ($):  0.00817657042122\n",
      "Got an exception in copy_ps_to_vm...\n",
      "[Errno 110] Connection timed out\n",
      "Copied PS binary to VM\n",
      "Current training loss: (126.32, 0.693042) current cost ($):  0.00830433752759\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (128.41, 0.693042) current cost ($):  0.00843210088075\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (130.45, 0.693042) current cost ($):  0.00856007072163\n",
      "Current training loss: (132.51, 0.693042) current cost ($):  0.00868785758177\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (134.6, 0.693042) current cost ($):  0.00881575609633\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (136.67, 0.693042) current cost ($):  0.00894339949849\n",
      "Current training loss: (138.75, 0.693042) current cost ($):  0.00907108222586\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (140.8, 0.693042) current cost ($):  0.00919890158857\n",
      "Current training loss: (142.8, 0.693042) current cost ($):  0.00932680253436\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (144.94, 0.693042) current cost ($):  0.00945456097946\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (147.03, 0.693042) current cost ($):  0.00958252940718\n",
      "Current training loss: (149.11, 0.693042) current cost ($):  0.00971027045377\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (151.1, 0.693042) current cost ($):  0.00983780938886\n",
      "Current training loss: (153.2, 0.693042) current cost ($):  0.00996583563436\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (155.32, 0.693042) current cost ($):  0.0100935673663\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (157.4, 0.693042) current cost ($):  0.0102213820185\n",
      "Current training loss: (159.53, 0.693042) current cost ($):  0.0103489257401\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (161.5, 0.693042) current cost ($):  0.010476579399\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (163.58, 0.693042) current cost ($):  0.0106042904198\n",
      "Current training loss: (165.59, 0.693042) current cost ($):  0.0107319545331\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (167.68, 0.693042) current cost ($):  0.0108594807346\n",
      "Current training loss: (169.7, 0.693042) current cost ($):  0.0109871472638\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (171.79, 0.693042) current cost ($):  0.0111148209349\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (173.82, 0.693042) current cost ($):  0.01124265528\n",
      "Current training loss: (175.87, 0.693042) current cost ($):  0.0113703781532\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (177.92, 0.693042) current cost ($):  0.0114982604848\n",
      "Current training loss: (179.95, 0.693042) current cost ($):  0.011625847999\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (181.99, 0.693042) current cost ($):  0.0117535356192\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (184.06, 0.693042) current cost ($):  0.0118811721987\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (186.12, 0.693042) current cost ($):  0.0121364349794\n",
      "Current training loss: (188.14, 0.693042) current cost ($):  0.0121367662046\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (190.19, 0.693042) current cost ($):  0.0123922221469\n",
      "Current training loss: (192.23, 0.693042) current cost ($):  0.0125198763832\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (194.27, 0.693042) current cost ($):  0.0126475448879\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (196.33, 0.693042) current cost ($):  0.0127751747207\n",
      "Current training loss: (198.36, 0.693042) current cost ($):  0.0129028522665\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (200.39, 0.693042) current cost ($):  0.013030502233\n",
      "Current training loss: (202.41, 0.693042) current cost ($):  0.0131583996839\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (204.46, 0.693042) current cost ($):  0.0132860584332\n",
      "Current training loss: (206.47, 0.693042) current cost ($):  0.0134137246586\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (208.47, 0.693042) current cost ($):  0.0135416600063\n",
      "Current training loss: (210.53, 0.693042) current cost ($):  0.0136695870879\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (212.58, 0.693042) current cost ($):  0.0137973861194\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (214.64, 0.693042) current cost ($):  0.0139250543809\n",
      "Current training loss: (216.68, 0.693042) current cost ($):  0.0140530107133\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (218.78, 0.693042) current cost ($):  0.0141808481127\n",
      "Current training loss: (220.87, 0.693042) current cost ($):  0.014308495344\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (222.89, 0.693042) current cost ($):  0.0144362143272\n",
      "PS has 1 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.10.1\"}\n",
      "Current training loss: (224.93, 0.693042) current cost ($):  0.0145640201813\n",
      "Current training loss: (226.9, 0.693042) current cost ($):  0.0146917672148\n",
      "PS has 5 lambdas\n",
      "Current training loss: (229.01, 0.693042) current cost ($):  0.0148197226507\n",
      "PS has 10 lambdas\n",
      "Current training loss: (231.61, 1.00286) current cost ($):  0.0149475694863\n",
      "Current training loss: (233.72, 1.39714) current cost ($):  0.0150754359542\n",
      "PS has 12 lambdas\n",
      "Current training loss: (235.83, 1.41393) current cost ($):  0.0152032868621\n",
      "PS has 12 lambdas\n",
      "Current training loss: (238.51, 1.31981) current cost ($):  0.0154585461935\n",
      "PS has 13 lambdas\n",
      "Current training loss: (240.86, 1.18116) current cost ($):  0.0155862434475\n",
      "PS has 9 lambdas\n",
      "Current training loss: (243.28, 1.13918) current cost ($):  0.0157141371908\n",
      "Current training loss: (245.77, 0.845578) current cost ($):  0.0158419055127\n",
      "PS has 13 lambdas\n",
      "Current training loss: (247.98, 0.643486) current cost ($):  0.0159694848519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS has 17 lambdas\n",
      "Current training loss: (250.68, 0.592716) current cost ($):  0.016224777324\n",
      "PS has 19 lambdas\n",
      "Current training loss: (253.51, 0.566219) current cost ($):  0.0163525360123\n",
      "PS has 21 lambdas\n",
      "Current training loss: (255.59, 0.548411) current cost ($):  0.0164804903692\n",
      "Current training loss: (258.16, 0.539712) current cost ($):  0.0166081509116\n",
      "PS has 25 lambdas\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "[Errno 110] Connection timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-189d14db1e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlr_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlr_task1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlr_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/camus/code/cirrus-1/python/frontend/cirrus/examples/cirrus.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_ps_to_vm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mps_ip_public\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mps_ip_public\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch_ps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mps_ip_public\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/camus/code/cirrus-1/python/frontend/cirrus/examples/cirrus.pyc\u001b[0m in \u001b[0;36mdefine_config\u001b[0;34m(self, ip)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparamiko\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSHClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_missing_host_key_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamiko\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoAddPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mps_username\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Defining configuration file\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mstdin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'echo \"%s\" > config_lr.txt'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/paramiko/client.pyc\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, hostname, port, username, password, pkey, key_filename, timeout, allow_agent, look_for_keys, compress, sock, gss_auth, gss_kex, gss_deleg_creds, gss_host, banner_timeout, auth_timeout, gss_trust_dns, passphrase)\u001b[0m\n\u001b[1;32m    336\u001b[0m                         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                     \u001b[0mretry_on_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m                     \u001b[0;31m# Break out of the loop on success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/paramiko/util.pyc\u001b[0m in \u001b[0;36mretry_on_signal\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/paramiko/client.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    336\u001b[0m                         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                     \u001b[0mretry_on_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m                     \u001b[0;31m# Break out of the loop on success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mmeth\u001b[0;34m(name, self, *args)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socketmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: [Errno 110] Connection timed out"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current training loss: (260.23, 0.532509) current cost ($):  0.0167359526934\n",
      "PS has 29 lambdas\n",
      "Current training loss: (262.57, 0.527916) current cost ($):  0.0169911452267\n",
      "PS has 35 lambdas\n",
      "Current training loss: (264.67, 0.522176) current cost ($):  0.0171190911655\n",
      "PS has 33 lambdas\n",
      "Current training loss: (267.01, 0.518097) current cost ($):  0.0172469091302\n",
      "Current training loss: (269.35, 0.514549) current cost ($):  0.0173746977226\n",
      "PS has 35 lambdas\n",
      "Current training loss: (271.4, 0.511556) current cost ($):  0.0175022831247\n",
      "PS has 39 lambdas\n",
      "Current training loss: (273.81, 0.509265) current cost ($):  0.0176301211015\n",
      "Current training loss: (276.06, 0.507352) current cost ($):  0.017757777374\n",
      "PS has 41 lambdas\n",
      "PS has 37 lambdas\n",
      "Current training loss: (278.4, 0.50585) current cost ($):  0.0180132694504\n",
      "Current training loss: (280.5, 0.504534) current cost ($):  0.0181408678596\n",
      "PS has 37 lambdas\n",
      "Current training loss: (282.77, 0.503513) current cost ($):  0.018268564916\n",
      "PS has 41 lambdas\n",
      "Current training loss: (284.83, 0.502505) current cost ($):  0.0183962125273\n",
      "Current training loss: (287.0, 0.501783) current cost ($):  0.0185238962119\n",
      "PS has 39 lambdas\n",
      "Current training loss: (289.42, 0.501186) current cost ($):  0.0186518211814\n",
      "Current training loss: (291.53, 0.500699) current cost ($):  0.018779696508\n",
      "PS has 37 lambdas\n",
      "Current training loss: (293.82, 0.500323) current cost ($):  0.0189075082883\n",
      "PS has 39 lambdas\n",
      "Current training loss: (295.89, 0.499984) current cost ($):  0.0190353857727\n",
      "Current training loss: (298.21, 0.499725) current cost ($):  0.0191629451757\n",
      "PS has 37 lambdas\n",
      "Current training loss: (300.32, 0.499433) current cost ($):  0.0192906122217\n",
      "PS has 35 lambdas\n",
      "Current training loss: (302.44, 0.49921) current cost ($):  0.0195459720542\n",
      "PS has 35 lambdas\n",
      "Current training loss: (304.55, 0.498998) current cost ($):  0.0196738753552\n",
      "Current training loss: (306.83, 0.498807) current cost ($):  0.0198015749797\n",
      "PS has 31 lambdas\n",
      "Current training loss: (309.1, 0.498585) current cost ($):  0.0199294986119\n",
      "PS has 31 lambdas\n",
      "Current training loss: (311.21, 0.498431) current cost ($):  0.0200574089179\n",
      "Current training loss: (313.3, 0.49828) current cost ($):  0.0201851325052\n",
      "PS has 25 lambdas\n",
      "Current training loss: (315.4, 0.498142) current cost ($):  0.0203128085923\n",
      "PS has 29 lambdas\n",
      "Current training loss: (317.86, 0.497974) current cost ($):  0.0204404994795\n",
      "Current training loss: (319.95, 0.49781) current cost ($):  0.0205684062754\n",
      "PS has 28 lambdas\n",
      "PS has 22 lambdas\n",
      "Current training loss: (322.51, 0.49773) current cost ($):  0.0208236667617\n",
      "Current training loss: (324.6, 0.497673) current cost ($):  0.0209513639549\n",
      "PS has 24 lambdas\n",
      "Current training loss: (327.28, 0.497696) current cost ($):  0.0210790835154\n",
      "PS has 24 lambdas\n",
      "Current training loss: (329.48, 0.497636) current cost ($):  0.0212067144727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "try:\n",
    "    lr_task.run()\n",
    "    lr_task1.run()\n",
    "except KeyboardInterrupt:\n",
    "    lr_task.kill()\n",
    "    lr_task1.kill()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock received kill command\n",
      "Mock is dead\n"
     ]
    }
   ],
   "source": [
    "mock_obj.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
